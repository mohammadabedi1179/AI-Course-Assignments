{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25559491",
   "metadata": {},
   "source": [
    "# Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbafcce",
   "metadata": {},
   "source": [
    "## Entropy is a measure of the uncertainty associated with a given distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a496f9d1",
   "metadata": {},
   "source": [
    "Let's explain Entropy clearly by example. Suppose we have a box with color balls in it. If we know that all of the balls are green, what color would be the ball we pull out of the box? it would be green obviously so the Entropy in this example is 0 and it means our data is pure and we don't have any uncertainty.\n",
    "what if we have added some red balls to the box? because we have mixed of color balls we are not certain about the color of the ball that would pull out but we know that the number of green balls is more than the number of red balls so the probability of green is more than red. \n",
    "what if we have added red balls till we have half red balls and half green balls? in this case, we are completely uncertain about the color of the ball because the number of the red and green ones are equal and our data is completely impure so Entropy is equal to the maximum in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62aa0682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"purity.jpg\" width=\"800\" height=\"600\" align=\"center\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "html1 = '<img src=\"purity.jpg\" width=\"800\" height=\"600\" align=\"center\"/>'\n",
    "HTML(html1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddc3d3a",
   "metadata": {},
   "source": [
    "## Dive into mathematics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1fc7b2",
   "metadata": {},
   "source": [
    "For every other case in between, we can compute the entropy of a distribution, like q(y), using the formula below, where C is the number of classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942ac2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Entropy.png\" width=\"400\" height=\"200\" style=\"margin-left:auto; margin-right:auto\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html1 = '<img src=\"Entropy.png\" width=\"400\" height=\"200\" style=\"margin-left:auto; margin-right:auto\"/>'\n",
    "HTML(html1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ecb092",
   "metadata": {},
   "source": [
    "Let's compute Entropy for 2 examples above:\n",
    "1. All balls are green:\n",
    "    We have only one class and its probability is 1 so the Entropy is 0.\n",
    "2. Half green, half red:\n",
    "    We have two classes with 0.5 probability which gives us Entropy equal to log(2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec84a71",
   "metadata": {},
   "source": [
    "# Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8628cb8",
   "metadata": {},
   "source": [
    "If we know the true distribution of a random variable, we can compute its Entropy. But, if that’s the case, why we train our data to predict unseen data?\n",
    "Actually we know the distribution of our data but we want to create a model that predict that distribution well enough.\n",
    "Let’s assume our data follow this other distribution p(y). But we know they are actually coming from the true (unknown) distribution q(y), right?\n",
    "If we compute entropy like this, we are actually computing the cross-entropy between both distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f58b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"cross_entropy.jpg\" width=\"600\" height=\"200\" align=\"center\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html1 = '<img src=\"cross_entropy.jpg\" width=\"600\" height=\"200\" align=\"center\"/>'\n",
    "HTML(html1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab54de65",
   "metadata": {},
   "source": [
    "If we can match p(y) to q(y) perfectly, the computed values for both cross-entropy and entropy will match as well.\n",
    "Since this is likely never happening, cross-entropy will have a BIGGER value than the entropy computed on the true distribution. We can compute the difference of Entropy and Cross Entropy by the formula below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96701375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"KL Divergence.jpg\" width=\"800\" height=\"200\" align=\"center\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html1 = '<img src=\"KL Divergence.jpg\" width=\"800\" height=\"200\" align=\"center\"/>'\n",
    "HTML(html1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87af3e8",
   "metadata": {},
   "source": [
    "In this case we want to define a model have a closest ditribution(p(y)) to the real distribution(q(y)) and if we are going to close these two distribution, the difference of Entropy and Cross Entropy is going down to 0 too. this is exactly same as what we are doing with loss function.\n",
    "### It looks for the best possible p(y), which is the one that minimizes the Cross Entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fce7e1",
   "metadata": {},
   "source": [
    "## Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "437ebf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5170595a",
   "metadata": {},
   "source": [
    "## Import Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f60a59f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('E:\\Educate\\Datasets\\Covid19 Syptoms\\Covid Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d4f43c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Breathing Problem</th>\n",
       "      <th>Fever</th>\n",
       "      <th>Dry Cough</th>\n",
       "      <th>Sore throat</th>\n",
       "      <th>Running Nose</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>Chronic Lung Disease</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Heart Disease</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>...</th>\n",
       "      <th>Fatigue</th>\n",
       "      <th>Gastrointestinal</th>\n",
       "      <th>Abroad travel</th>\n",
       "      <th>Contact with COVID Patient</th>\n",
       "      <th>Attended Large Gathering</th>\n",
       "      <th>Visited Public Exposed Places</th>\n",
       "      <th>Family working in Public Exposed Places</th>\n",
       "      <th>Wearing Masks</th>\n",
       "      <th>Sanitization from Market</th>\n",
       "      <th>COVID-19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5433</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5434 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Breathing Problem Fever Dry Cough Sore throat Running Nose Asthma  \\\n",
       "0                  Yes   Yes       Yes         Yes          Yes     No   \n",
       "1                  Yes   Yes       Yes         Yes           No    Yes   \n",
       "2                  Yes   Yes       Yes         Yes          Yes    Yes   \n",
       "3                  Yes   Yes       Yes          No           No    Yes   \n",
       "4                  Yes   Yes       Yes         Yes          Yes     No   \n",
       "...                ...   ...       ...         ...          ...    ...   \n",
       "5429               Yes   Yes        No         Yes          Yes    Yes   \n",
       "5430               Yes   Yes       Yes          No          Yes    Yes   \n",
       "5431               Yes   Yes       Yes          No           No     No   \n",
       "5432               Yes   Yes       Yes          No          Yes     No   \n",
       "5433               Yes   Yes       Yes          No          Yes    Yes   \n",
       "\n",
       "     Chronic Lung Disease Headache Heart Disease Diabetes  ... Fatigue   \\\n",
       "0                      No       No            No      Yes  ...      Yes   \n",
       "1                     Yes      Yes            No       No  ...      Yes   \n",
       "2                     Yes      Yes            No      Yes  ...      Yes   \n",
       "3                      No       No           Yes      Yes  ...       No   \n",
       "4                     Yes      Yes           Yes      Yes  ...       No   \n",
       "...                   ...      ...           ...      ...  ...      ...   \n",
       "5429                  Yes       No            No       No  ...      Yes   \n",
       "5430                   No      Yes            No      Yes  ...      Yes   \n",
       "5431                   No       No           Yes       No  ...       No   \n",
       "5432                   No      Yes           Yes       No  ...       No   \n",
       "5433                   No      Yes            No      Yes  ...      Yes   \n",
       "\n",
       "     Gastrointestinal  Abroad travel Contact with COVID Patient  \\\n",
       "0                  Yes            No                        Yes   \n",
       "1                   No            No                         No   \n",
       "2                  Yes           Yes                         No   \n",
       "3                   No           Yes                         No   \n",
       "4                  Yes            No                        Yes   \n",
       "...                ...           ...                        ...   \n",
       "5429               Yes            No                         No   \n",
       "5430                No            No                         No   \n",
       "5431                No            No                         No   \n",
       "5432                No            No                         No   \n",
       "5433                No            No                         No   \n",
       "\n",
       "     Attended Large Gathering Visited Public Exposed Places  \\\n",
       "0                          No                           Yes   \n",
       "1                         Yes                           Yes   \n",
       "2                          No                            No   \n",
       "3                         Yes                           Yes   \n",
       "4                          No                           Yes   \n",
       "...                       ...                           ...   \n",
       "5429                       No                            No   \n",
       "5430                       No                            No   \n",
       "5431                       No                            No   \n",
       "5432                       No                            No   \n",
       "5433                       No                            No   \n",
       "\n",
       "     Family working in Public Exposed Places Wearing Masks  \\\n",
       "0                                        Yes            No   \n",
       "1                                         No            No   \n",
       "2                                         No            No   \n",
       "3                                         No            No   \n",
       "4                                         No            No   \n",
       "...                                      ...           ...   \n",
       "5429                                      No            No   \n",
       "5430                                      No            No   \n",
       "5431                                      No            No   \n",
       "5432                                      No            No   \n",
       "5433                                      No            No   \n",
       "\n",
       "     Sanitization from Market COVID-19  \n",
       "0                          No      Yes  \n",
       "1                          No      Yes  \n",
       "2                          No      Yes  \n",
       "3                          No      Yes  \n",
       "4                          No      Yes  \n",
       "...                       ...      ...  \n",
       "5429                       No      Yes  \n",
       "5430                       No      Yes  \n",
       "5431                       No       No  \n",
       "5432                       No       No  \n",
       "5433                       No       No  \n",
       "\n",
       "[5434 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f698786",
   "metadata": {},
   "source": [
    "## Convert categorical data to numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc6e7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Breathing Problem</th>\n",
       "      <th>Fever</th>\n",
       "      <th>Dry Cough</th>\n",
       "      <th>Sore throat</th>\n",
       "      <th>Running Nose</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>Chronic Lung Disease</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Heart Disease</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>...</th>\n",
       "      <th>Fatigue</th>\n",
       "      <th>Gastrointestinal</th>\n",
       "      <th>Abroad travel</th>\n",
       "      <th>Contact with COVID Patient</th>\n",
       "      <th>Attended Large Gathering</th>\n",
       "      <th>Visited Public Exposed Places</th>\n",
       "      <th>Family working in Public Exposed Places</th>\n",
       "      <th>Wearing Masks</th>\n",
       "      <th>Sanitization from Market</th>\n",
       "      <th>COVID-19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5433</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5434 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Breathing Problem  Fever  Dry Cough  Sore throat  Running Nose  Asthma  \\\n",
       "0                     1      1          1            1             1       0   \n",
       "1                     1      1          1            1             0       1   \n",
       "2                     1      1          1            1             1       1   \n",
       "3                     1      1          1            0             0       1   \n",
       "4                     1      1          1            1             1       0   \n",
       "...                 ...    ...        ...          ...           ...     ...   \n",
       "5429                  1      1          0            1             1       1   \n",
       "5430                  1      1          1            0             1       1   \n",
       "5431                  1      1          1            0             0       0   \n",
       "5432                  1      1          1            0             1       0   \n",
       "5433                  1      1          1            0             1       1   \n",
       "\n",
       "      Chronic Lung Disease  Headache  Heart Disease  Diabetes  ...  Fatigue   \\\n",
       "0                        0         0              0         1  ...         1   \n",
       "1                        1         1              0         0  ...         1   \n",
       "2                        1         1              0         1  ...         1   \n",
       "3                        0         0              1         1  ...         0   \n",
       "4                        1         1              1         1  ...         0   \n",
       "...                    ...       ...            ...       ...  ...       ...   \n",
       "5429                     1         0              0         0  ...         1   \n",
       "5430                     0         1              0         1  ...         1   \n",
       "5431                     0         0              1         0  ...         0   \n",
       "5432                     0         1              1         0  ...         0   \n",
       "5433                     0         1              0         1  ...         1   \n",
       "\n",
       "      Gastrointestinal   Abroad travel  Contact with COVID Patient  \\\n",
       "0                     1              0                           1   \n",
       "1                     0              0                           0   \n",
       "2                     1              1                           0   \n",
       "3                     0              1                           0   \n",
       "4                     1              0                           1   \n",
       "...                 ...            ...                         ...   \n",
       "5429                  1              0                           0   \n",
       "5430                  0              0                           0   \n",
       "5431                  0              0                           0   \n",
       "5432                  0              0                           0   \n",
       "5433                  0              0                           0   \n",
       "\n",
       "      Attended Large Gathering  Visited Public Exposed Places  \\\n",
       "0                            0                              1   \n",
       "1                            1                              1   \n",
       "2                            0                              0   \n",
       "3                            1                              1   \n",
       "4                            0                              1   \n",
       "...                        ...                            ...   \n",
       "5429                         0                              0   \n",
       "5430                         0                              0   \n",
       "5431                         0                              0   \n",
       "5432                         0                              0   \n",
       "5433                         0                              0   \n",
       "\n",
       "      Family working in Public Exposed Places  Wearing Masks  \\\n",
       "0                                           1              0   \n",
       "1                                           0              0   \n",
       "2                                           0              0   \n",
       "3                                           0              0   \n",
       "4                                           0              0   \n",
       "...                                       ...            ...   \n",
       "5429                                        0              0   \n",
       "5430                                        0              0   \n",
       "5431                                        0              0   \n",
       "5432                                        0              0   \n",
       "5433                                        0              0   \n",
       "\n",
       "      Sanitization from Market  COVID-19  \n",
       "0                            0         1  \n",
       "1                            0         1  \n",
       "2                            0         1  \n",
       "3                            0         1  \n",
       "4                            0         1  \n",
       "...                        ...       ...  \n",
       "5429                         0         1  \n",
       "5430                         0         1  \n",
       "5431                         0         0  \n",
       "5432                         0         0  \n",
       "5433                         0         0  \n",
       "\n",
       "[5434 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = dict(Yes = 1, No = 0)\n",
    "new_df = df\n",
    "for column in new_df.columns:\n",
    "    new_df[column] = new_df[column].map(mapping)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8839f0bf",
   "metadata": {},
   "source": [
    "## Check for missing informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7f67552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in new_df:\n",
    "    for j in new_df[i]:\n",
    "        if new_df[i][j] not in [0,1]:\n",
    "            counter += 1\n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1888f566",
   "metadata": {},
   "source": [
    "## Number of positive and negative tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "440d854a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"378.44375pt\" height=\"247.985312pt\" viewBox=\"0 0 378.44375 247.985312\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-04-01T16:23:39.108069</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.0, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 247.985312 \nL 378.44375 247.985312 \nL 378.44375 0 \nL 0 0 \nL 0 247.985312 \nz\n\" style=\"fill: none\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 36.44375 224.64 \nL 371.24375 224.64 \nL 371.24375 7.2 \nL 36.44375 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 51.661932 224.64 \nL 82.098295 224.64 \nL 82.098295 174.982896 \nL 51.661932 174.982896 \nz\n\" clip-path=\"url(#p9d87c2e045)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 82.098295 224.64 \nL 112.534659 224.64 \nL 112.534659 224.64 \nL 82.098295 224.64 \nz\n\" clip-path=\"url(#p9d87c2e045)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 112.534659 224.64 \nL 142.971023 224.64 \nL 142.971023 224.64 \nL 112.534659 224.64 \nz\n\" clip-path=\"url(#p9d87c2e045)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 142.971023 224.64 \nL 173.407386 224.64 \nL 173.407386 224.64 \nL 142.971023 224.64 \nz\n\" clip-path=\"url(#p9d87c2e045)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path d=\"M 173.407386 224.64 \nL 203.84375 224.64 \nL 203.84375 224.64 \nL 173.407386 224.64 \nz\n\" clip-path=\"url(#p9d87c2e045)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 203.84375 224.64 \nL 234.280114 224.64 \nL 234.280114 224.64 \nL 203.84375 224.64 \nz\n\" clip-path=\"url(#p9d87c2e045)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 234.280114 224.64 \nL 264.716477 224.64 \nL 264.716477 224.64 \nL 234.280114 224.64 \nz\n\" clip-path=\"url(#p9d87c2e045)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 264.716477 224.64 \nL 295.152841 224.64 \nL 295.152841 224.64 \nL 264.716477 224.64 \nz\n\" clip-path=\"url(#p9d87c2e045)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 295.152841 224.64 \nL 325.589205 224.64 \nL 325.589205 224.64 \nL 295.152841 224.64 \nz\n\" clip-path=\"url(#p9d87c2e045)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 325.589205 224.64 \nL 356.025568 224.64 \nL 356.025568 17.554286 \nL 325.589205 17.554286 \nz\n\" clip-path=\"url(#p9d87c2e045)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m94217182bc\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m94217182bc\" x=\"51.661932\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.0 -->\n      <g transform=\"translate(44.711932 238.797812)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"ArialMT-30\" d=\"M 266 2259 \nQ 266 3072 433 3567 \nQ 600 4063 929 4331 \nQ 1259 4600 1759 4600 \nQ 2128 4600 2406 4451 \nQ 2684 4303 2865 4023 \nQ 3047 3744 3150 3342 \nQ 3253 2941 3253 2259 \nQ 3253 1453 3087 958 \nQ 2922 463 2592 192 \nQ 2263 -78 1759 -78 \nQ 1097 -78 719 397 \nQ 266 969 266 2259 \nz\nM 844 2259 \nQ 844 1131 1108 757 \nQ 1372 384 1759 384 \nQ 2147 384 2411 759 \nQ 2675 1134 2675 2259 \nQ 2675 3391 2411 3762 \nQ 2147 4134 1753 4134 \nQ 1366 4134 1134 3806 \nQ 844 3388 844 2259 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-2e\" d=\"M 581 0 \nL 581 641 \nL 1222 641 \nL 1222 0 \nL 581 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m94217182bc\" x=\"112.534659\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.2 -->\n      <g transform=\"translate(105.584659 238.797812)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"ArialMT-32\" d=\"M 3222 541 \nL 3222 0 \nL 194 0 \nQ 188 203 259 391 \nQ 375 700 629 1000 \nQ 884 1300 1366 1694 \nQ 2113 2306 2375 2664 \nQ 2638 3022 2638 3341 \nQ 2638 3675 2398 3904 \nQ 2159 4134 1775 4134 \nQ 1369 4134 1125 3890 \nQ 881 3647 878 3216 \nL 300 3275 \nQ 359 3922 746 4261 \nQ 1134 4600 1788 4600 \nQ 2447 4600 2831 4234 \nQ 3216 3869 3216 3328 \nQ 3216 3053 3103 2787 \nQ 2991 2522 2730 2228 \nQ 2469 1934 1863 1422 \nQ 1356 997 1212 845 \nQ 1069 694 975 541 \nL 3222 541 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-32\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m94217182bc\" x=\"173.407386\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.4 -->\n      <g transform=\"translate(166.457386 238.797812)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"ArialMT-34\" d=\"M 2069 0 \nL 2069 1097 \nL 81 1097 \nL 81 1613 \nL 2172 4581 \nL 2631 4581 \nL 2631 1613 \nL 3250 1613 \nL 3250 1097 \nL 2631 1097 \nL 2631 0 \nL 2069 0 \nz\nM 2069 1613 \nL 2069 3678 \nL 634 1613 \nL 2069 1613 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-34\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m94217182bc\" x=\"234.280114\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.6 -->\n      <g transform=\"translate(227.330114 238.797812)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"ArialMT-36\" d=\"M 3184 3459 \nL 2625 3416 \nQ 2550 3747 2413 3897 \nQ 2184 4138 1850 4138 \nQ 1581 4138 1378 3988 \nQ 1113 3794 959 3422 \nQ 806 3050 800 2363 \nQ 1003 2672 1297 2822 \nQ 1591 2972 1913 2972 \nQ 2475 2972 2870 2558 \nQ 3266 2144 3266 1488 \nQ 3266 1056 3080 686 \nQ 2894 316 2569 119 \nQ 2244 -78 1831 -78 \nQ 1128 -78 684 439 \nQ 241 956 241 2144 \nQ 241 3472 731 4075 \nQ 1159 4600 1884 4600 \nQ 2425 4600 2770 4297 \nQ 3116 3994 3184 3459 \nz\nM 888 1484 \nQ 888 1194 1011 928 \nQ 1134 663 1356 523 \nQ 1578 384 1822 384 \nQ 2178 384 2434 671 \nQ 2691 959 2691 1453 \nQ 2691 1928 2437 2201 \nQ 2184 2475 1800 2475 \nQ 1419 2475 1153 2201 \nQ 888 1928 888 1484 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-36\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m94217182bc\" x=\"295.152841\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.8 -->\n      <g transform=\"translate(288.202841 238.797812)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"ArialMT-38\" d=\"M 1131 2484 \nQ 781 2613 612 2850 \nQ 444 3088 444 3419 \nQ 444 3919 803 4259 \nQ 1163 4600 1759 4600 \nQ 2359 4600 2725 4251 \nQ 3091 3903 3091 3403 \nQ 3091 3084 2923 2848 \nQ 2756 2613 2416 2484 \nQ 2838 2347 3058 2040 \nQ 3278 1734 3278 1309 \nQ 3278 722 2862 322 \nQ 2447 -78 1769 -78 \nQ 1091 -78 675 323 \nQ 259 725 259 1325 \nQ 259 1772 486 2073 \nQ 713 2375 1131 2484 \nz\nM 1019 3438 \nQ 1019 3113 1228 2906 \nQ 1438 2700 1772 2700 \nQ 2097 2700 2305 2904 \nQ 2513 3109 2513 3406 \nQ 2513 3716 2298 3927 \nQ 2084 4138 1766 4138 \nQ 1444 4138 1231 3931 \nQ 1019 3725 1019 3438 \nz\nM 838 1322 \nQ 838 1081 952 856 \nQ 1066 631 1291 507 \nQ 1516 384 1775 384 \nQ 2178 384 2440 643 \nQ 2703 903 2703 1303 \nQ 2703 1709 2433 1975 \nQ 2163 2241 1756 2241 \nQ 1359 2241 1098 1978 \nQ 838 1716 838 1322 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-38\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m94217182bc\" x=\"356.025568\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1.0 -->\n      <g transform=\"translate(349.075568 238.797812)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"ArialMT-31\" d=\"M 2384 0 \nL 1822 0 \nL 1822 3584 \nQ 1619 3391 1289 3197 \nQ 959 3003 697 2906 \nL 697 3450 \nQ 1169 3672 1522 3987 \nQ 1875 4303 2022 4600 \nL 2384 4600 \nL 2384 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"mfc16ea800e\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mfc16ea800e\" x=\"36.44375\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(23.882813 228.218906)scale(0.1 -0.1)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#mfc16ea800e\" x=\"36.44375\" y=\"177.392518\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 1000 -->\n      <g transform=\"translate(7.2 180.971424)scale(0.1 -0.1)\">\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#mfc16ea800e\" x=\"36.44375\" y=\"130.145036\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 2000 -->\n      <g transform=\"translate(7.2 133.723942)scale(0.1 -0.1)\">\n       <use xlink:href=\"#ArialMT-32\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#mfc16ea800e\" x=\"36.44375\" y=\"82.897554\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 3000 -->\n      <g transform=\"translate(7.2 86.47646)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"ArialMT-33\" d=\"M 269 1209 \nL 831 1284 \nQ 928 806 1161 595 \nQ 1394 384 1728 384 \nQ 2125 384 2398 659 \nQ 2672 934 2672 1341 \nQ 2672 1728 2419 1979 \nQ 2166 2231 1775 2231 \nQ 1616 2231 1378 2169 \nL 1441 2663 \nQ 1497 2656 1531 2656 \nQ 1891 2656 2178 2843 \nQ 2466 3031 2466 3422 \nQ 2466 3731 2256 3934 \nQ 2047 4138 1716 4138 \nQ 1388 4138 1169 3931 \nQ 950 3725 888 3313 \nL 325 3413 \nQ 428 3978 793 4289 \nQ 1159 4600 1703 4600 \nQ 2078 4600 2393 4439 \nQ 2709 4278 2876 4000 \nQ 3044 3722 3044 3409 \nQ 3044 3113 2884 2869 \nQ 2725 2625 2413 2481 \nQ 2819 2388 3044 2092 \nQ 3269 1797 3269 1353 \nQ 3269 753 2831 336 \nQ 2394 -81 1725 -81 \nQ 1122 -81 723 278 \nQ 325 638 269 1209 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-33\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#mfc16ea800e\" x=\"36.44375\" y=\"35.650071\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 4000 -->\n      <g transform=\"translate(7.2 39.228978)scale(0.1 -0.1)\">\n       <use xlink:href=\"#ArialMT-34\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 36.44375 224.64 \nL 36.44375 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 371.24375 224.64 \nL 371.24375 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 36.44375 224.64 \nL 371.24375 224.64 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 36.44375 7.2 \nL 371.24375 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p9d87c2e045\">\n   <rect x=\"36.44375\" y=\"7.2\" width=\"334.8\" height=\"217.44\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(new_df[\"COVID-19\"])\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda4786",
   "metadata": {},
   "source": [
    "## Split data to test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "796fcd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train , test = train_test_split(new_df , test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87a64f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fearure_columns = ['Breathing Problem', 'Fever', 'Dry Cough', 'Sore throat',\n",
    "       'Running Nose', 'Asthma', 'Chronic Lung Disease', 'Headache',\n",
    "       'Heart Disease', 'Diabetes', 'Hyper Tension', 'Fatigue ',\n",
    "       'Gastrointestinal ', 'Abroad travel', 'Contact with COVID Patient',\n",
    "       'Attended Large Gathering', 'Visited Public Exposed Places',\n",
    "       'Family working in Public Exposed Places', 'Wearing Masks',\n",
    "       'Sanitization from Market']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffbf6ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , y_train , x_test, y_test = train.loc[: , fearure_columns] , train.loc[: , 'COVID-19'] ,test.loc[: , fearure_columns] , test.loc[: , 'COVID-19']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7385b4e5",
   "metadata": {},
   "source": [
    "## Develope Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4190fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='sigmoid', input_shape=(20,)))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c5a0d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                210       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "967c9c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-2), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4612e159",
   "metadata": {},
   "source": [
    "## Loss Function: Binary Cross Entropy\n",
    "During training, the classifier uses each of the N points in its training set to compute the cross-entropy loss, effectively fitting the distribution p(y)! Since the probability of each point is 1/N, cross-entropy is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2a9c91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"LFBCE.jpg\" width=\"600\" height=\"150\" align=\"center\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html1 = '<img src=\"LFBCE.jpg\" width=\"600\" height=\"150\" align=\"center\"/>'\n",
    "HTML(html1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca08fc9e",
   "metadata": {},
   "source": [
    "For this example, we have two classes Positive COVID-19 infection or Negative and we are going to predict the probability of infection with given symptoms so if someone infect by the virus, the class value is equal to 1 and if not, the class value would be equal to 0. There are only two cases and the sum of probability of infection and not infected must be equal to 1 and p(y) is the probability of infection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d00ef4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"classes.jpg\" width=\"400\" height=\"100\" align=\"center\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html1 = '<img src=\"classes.jpg\" width=\"400\" height=\"100\" align=\"center\"/>'\n",
    "HTML(html1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1022c96",
   "metadata": {},
   "source": [
    "The final step is to compute the average of all points in both classes, Positive and Negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acc16b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"average sum.jpg\" width=\"600\" height=\"150\" align=\"center\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html1 = '<img src=\"average sum.jpg\" width=\"600\" height=\"150\" align=\"center\"/>'\n",
    "HTML(html1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834da914",
   "metadata": {},
   "source": [
    "Finally, with a little bit of manipulation, we can take any point, either from the Positive or Negative classes, under the same formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3557937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"BCE.jpg\" width=\"600\" height=\"150\" align=\"center\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html1 = '<img src=\"BCE.jpg\" width=\"600\" height=\"150\" align=\"center\"/>'\n",
    "HTML(html1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6d5b65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "17/17 [==============================] - 4s 46ms/step - loss: 0.4655 - accuracy: 0.8098 - val_loss: 0.4503 - val_accuracy: 0.7939\n",
      "Epoch 2/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3938 - accuracy: 0.8104 - val_loss: 0.3708 - val_accuracy: 0.8123\n",
      "Epoch 3/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3207 - accuracy: 0.8364 - val_loss: 0.2996 - val_accuracy: 0.8454\n",
      "Epoch 4/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2541 - accuracy: 0.8896 - val_loss: 0.2448 - val_accuracy: 0.9062\n",
      "Epoch 5/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2064 - accuracy: 0.9250 - val_loss: 0.2078 - val_accuracy: 0.9246\n",
      "Epoch 6/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1748 - accuracy: 0.9381 - val_loss: 0.1880 - val_accuracy: 0.9264\n",
      "Epoch 7/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9489 - val_loss: 0.1698 - val_accuracy: 0.9384\n",
      "Epoch 8/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1391 - accuracy: 0.9510 - val_loss: 0.1557 - val_accuracy: 0.9393\n",
      "Epoch 9/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1275 - accuracy: 0.9524 - val_loss: 0.1481 - val_accuracy: 0.9430\n",
      "Epoch 10/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1201 - accuracy: 0.9556 - val_loss: 0.1368 - val_accuracy: 0.9485\n",
      "Epoch 11/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1131 - accuracy: 0.9600 - val_loss: 0.1285 - val_accuracy: 0.9586\n",
      "Epoch 12/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1054 - accuracy: 0.9699 - val_loss: 0.1237 - val_accuracy: 0.9604\n",
      "Epoch 13/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1010 - accuracy: 0.9683 - val_loss: 0.1218 - val_accuracy: 0.9641\n",
      "Epoch 14/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0968 - accuracy: 0.9689 - val_loss: 0.1161 - val_accuracy: 0.9623\n",
      "Epoch 15/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 0.9699 - val_loss: 0.1119 - val_accuracy: 0.9623\n",
      "Epoch 16/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0899 - accuracy: 0.9706 - val_loss: 0.1075 - val_accuracy: 0.9632\n",
      "Epoch 17/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0873 - accuracy: 0.9708 - val_loss: 0.1064 - val_accuracy: 0.9632\n",
      "Epoch 18/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 0.9717 - val_loss: 0.1049 - val_accuracy: 0.9650\n",
      "Epoch 19/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9708 - val_loss: 0.1009 - val_accuracy: 0.9586\n",
      "Epoch 20/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9706 - val_loss: 0.0982 - val_accuracy: 0.9623\n",
      "Epoch 21/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0799 - accuracy: 0.9710 - val_loss: 0.0971 - val_accuracy: 0.9623\n",
      "Epoch 22/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0791 - accuracy: 0.9719 - val_loss: 0.0958 - val_accuracy: 0.9595\n",
      "Epoch 23/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9724 - val_loss: 0.0941 - val_accuracy: 0.9632\n",
      "Epoch 24/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9712 - val_loss: 0.0973 - val_accuracy: 0.9650\n",
      "Epoch 25/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0749 - accuracy: 0.9735 - val_loss: 0.0927 - val_accuracy: 0.9522\n",
      "Epoch 26/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0777 - accuracy: 0.9685 - val_loss: 0.0911 - val_accuracy: 0.9604\n",
      "Epoch 27/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0764 - accuracy: 0.9676 - val_loss: 0.0933 - val_accuracy: 0.9650\n",
      "Epoch 28/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0726 - accuracy: 0.9733 - val_loss: 0.0915 - val_accuracy: 0.9650\n",
      "Epoch 29/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9731 - val_loss: 0.0890 - val_accuracy: 0.9650\n",
      "Epoch 30/150\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0712 - accuracy: 0.9738 - val_loss: 0.0867 - val_accuracy: 0.9632\n",
      "Epoch 31/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9724 - val_loss: 0.0862 - val_accuracy: 0.9650\n",
      "Epoch 32/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9731 - val_loss: 0.0851 - val_accuracy: 0.9641\n",
      "Epoch 33/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9724 - val_loss: 0.0837 - val_accuracy: 0.9595\n",
      "Epoch 34/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.9735 - val_loss: 0.0836 - val_accuracy: 0.9650\n",
      "Epoch 35/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9752 - val_loss: 0.0833 - val_accuracy: 0.9650\n",
      "Epoch 36/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9756 - val_loss: 0.0820 - val_accuracy: 0.9650\n",
      "Epoch 37/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9735 - val_loss: 0.0805 - val_accuracy: 0.9641\n",
      "Epoch 38/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9749 - val_loss: 0.0816 - val_accuracy: 0.9650\n",
      "Epoch 39/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9738 - val_loss: 0.0790 - val_accuracy: 0.9696\n",
      "Epoch 40/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9742 - val_loss: 0.0780 - val_accuracy: 0.9641\n",
      "Epoch 41/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9763 - val_loss: 0.0785 - val_accuracy: 0.9696\n",
      "Epoch 42/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9752 - val_loss: 0.0763 - val_accuracy: 0.9696\n",
      "Epoch 43/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.9756 - val_loss: 0.0766 - val_accuracy: 0.9696\n",
      "Epoch 44/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.9768 - val_loss: 0.0747 - val_accuracy: 0.9696\n",
      "Epoch 45/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9756 - val_loss: 0.0746 - val_accuracy: 0.9687\n",
      "Epoch 46/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9756 - val_loss: 0.0749 - val_accuracy: 0.9696\n",
      "Epoch 47/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9752 - val_loss: 0.0732 - val_accuracy: 0.9696\n",
      "Epoch 48/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9758 - val_loss: 0.0722 - val_accuracy: 0.9687\n",
      "Epoch 49/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9765 - val_loss: 0.0707 - val_accuracy: 0.9696\n",
      "Epoch 50/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.9752 - val_loss: 0.0709 - val_accuracy: 0.9696\n",
      "Epoch 51/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9752 - val_loss: 0.0683 - val_accuracy: 0.9761\n",
      "Epoch 52/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9763 - val_loss: 0.0687 - val_accuracy: 0.9761\n",
      "Epoch 53/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9791 - val_loss: 0.0715 - val_accuracy: 0.9733\n",
      "Epoch 54/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9779 - val_loss: 0.0723 - val_accuracy: 0.9678\n",
      "Epoch 55/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9770 - val_loss: 0.0695 - val_accuracy: 0.9733\n",
      "Epoch 56/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9788 - val_loss: 0.0678 - val_accuracy: 0.9724\n",
      "Epoch 57/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9765 - val_loss: 0.0660 - val_accuracy: 0.9733\n",
      "Epoch 58/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9777 - val_loss: 0.0653 - val_accuracy: 0.9742\n",
      "Epoch 59/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9784 - val_loss: 0.0652 - val_accuracy: 0.9761\n",
      "Epoch 60/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9795 - val_loss: 0.0656 - val_accuracy: 0.9742\n",
      "Epoch 61/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9791 - val_loss: 0.0660 - val_accuracy: 0.9715\n",
      "Epoch 62/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9802 - val_loss: 0.0654 - val_accuracy: 0.9724\n",
      "Epoch 63/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.9770 - val_loss: 0.0623 - val_accuracy: 0.9761\n",
      "Epoch 64/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 0.9786 - val_loss: 0.0617 - val_accuracy: 0.9761\n",
      "Epoch 65/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9807 - val_loss: 0.0631 - val_accuracy: 0.9788\n",
      "Epoch 66/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9814 - val_loss: 0.0614 - val_accuracy: 0.9798\n",
      "Epoch 67/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9811 - val_loss: 0.0614 - val_accuracy: 0.9798\n",
      "Epoch 68/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9781 - val_loss: 0.0609 - val_accuracy: 0.9798\n",
      "Epoch 69/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9807 - val_loss: 0.0592 - val_accuracy: 0.9770\n",
      "Epoch 70/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9802 - val_loss: 0.0645 - val_accuracy: 0.9678\n",
      "Epoch 71/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0483 - accuracy: 0.9798 - val_loss: 0.0609 - val_accuracy: 0.9788\n",
      "Epoch 72/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9811 - val_loss: 0.0596 - val_accuracy: 0.9788\n",
      "Epoch 73/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.9814 - val_loss: 0.0604 - val_accuracy: 0.9798\n",
      "Epoch 74/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9809 - val_loss: 0.0578 - val_accuracy: 0.9807\n",
      "Epoch 75/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9795 - val_loss: 0.0581 - val_accuracy: 0.9807\n",
      "Epoch 76/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9827 - val_loss: 0.0575 - val_accuracy: 0.9807\n",
      "Epoch 77/150\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.9818 - val_loss: 0.0592 - val_accuracy: 0.9788\n",
      "Epoch 78/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 0.9823 - val_loss: 0.0564 - val_accuracy: 0.9807\n",
      "Epoch 79/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9827 - val_loss: 0.0573 - val_accuracy: 0.9807\n",
      "Epoch 80/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9823 - val_loss: 0.0561 - val_accuracy: 0.9807\n",
      "Epoch 81/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9832 - val_loss: 0.0585 - val_accuracy: 0.9733\n",
      "Epoch 82/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0448 - accuracy: 0.9811 - val_loss: 0.0557 - val_accuracy: 0.9807\n",
      "Epoch 83/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.9821 - val_loss: 0.0583 - val_accuracy: 0.9742\n",
      "Epoch 84/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9823 - val_loss: 0.0556 - val_accuracy: 0.9798\n",
      "Epoch 85/150\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 0.9825 - val_loss: 0.0545 - val_accuracy: 0.9807\n",
      "Epoch 86/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9823 - val_loss: 0.0554 - val_accuracy: 0.9807\n",
      "Epoch 87/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9834 - val_loss: 0.0558 - val_accuracy: 0.9742\n",
      "Epoch 88/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9825 - val_loss: 0.0548 - val_accuracy: 0.9807\n",
      "Epoch 89/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9821 - val_loss: 0.0531 - val_accuracy: 0.9807\n",
      "Epoch 90/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9814 - val_loss: 0.0552 - val_accuracy: 0.9798\n",
      "Epoch 91/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 0.9830 - val_loss: 0.0532 - val_accuracy: 0.9807\n",
      "Epoch 92/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9823 - val_loss: 0.0541 - val_accuracy: 0.9798\n",
      "Epoch 93/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9832 - val_loss: 0.0533 - val_accuracy: 0.9807\n",
      "Epoch 94/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9832 - val_loss: 0.0531 - val_accuracy: 0.9798\n",
      "Epoch 95/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9825 - val_loss: 0.0529 - val_accuracy: 0.9798\n",
      "Epoch 96/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9825 - val_loss: 0.0520 - val_accuracy: 0.9807\n",
      "Epoch 97/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9830 - val_loss: 0.0552 - val_accuracy: 0.9742\n",
      "Epoch 98/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9816 - val_loss: 0.0525 - val_accuracy: 0.9798\n",
      "Epoch 99/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9830 - val_loss: 0.0523 - val_accuracy: 0.9807\n",
      "Epoch 100/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9832 - val_loss: 0.0526 - val_accuracy: 0.9807\n",
      "Epoch 101/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9832 - val_loss: 0.0516 - val_accuracy: 0.9807\n",
      "Epoch 102/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9825 - val_loss: 0.0531 - val_accuracy: 0.9742\n",
      "Epoch 103/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9823 - val_loss: 0.0510 - val_accuracy: 0.9807\n",
      "Epoch 104/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9832 - val_loss: 0.0509 - val_accuracy: 0.9807\n",
      "Epoch 105/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9821 - val_loss: 0.0530 - val_accuracy: 0.9742\n",
      "Epoch 106/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9830 - val_loss: 0.0509 - val_accuracy: 0.9807\n",
      "Epoch 107/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9811 - val_loss: 0.0494 - val_accuracy: 0.9807\n",
      "Epoch 108/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9832 - val_loss: 0.0505 - val_accuracy: 0.9807\n",
      "Epoch 109/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9832 - val_loss: 0.0492 - val_accuracy: 0.9788\n",
      "Epoch 110/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9834 - val_loss: 0.0533 - val_accuracy: 0.9742\n",
      "Epoch 111/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9823 - val_loss: 0.0485 - val_accuracy: 0.9807\n",
      "Epoch 112/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0397 - accuracy: 0.9825 - val_loss: 0.0485 - val_accuracy: 0.9788\n",
      "Epoch 113/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9832 - val_loss: 0.0493 - val_accuracy: 0.9807\n",
      "Epoch 114/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9825 - val_loss: 0.0480 - val_accuracy: 0.9807\n",
      "Epoch 115/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9832 - val_loss: 0.0508 - val_accuracy: 0.9798\n",
      "Epoch 116/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9825 - val_loss: 0.0491 - val_accuracy: 0.9807\n",
      "Epoch 117/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9832 - val_loss: 0.0489 - val_accuracy: 0.9807\n",
      "Epoch 118/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9832 - val_loss: 0.0486 - val_accuracy: 0.9807\n",
      "Epoch 119/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9825 - val_loss: 0.0490 - val_accuracy: 0.9807\n",
      "Epoch 120/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9832 - val_loss: 0.0482 - val_accuracy: 0.9807\n",
      "Epoch 121/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9811 - val_loss: 0.0528 - val_accuracy: 0.9733\n",
      "Epoch 122/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9814 - val_loss: 0.0478 - val_accuracy: 0.9807\n",
      "Epoch 123/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9827 - val_loss: 0.0508 - val_accuracy: 0.9742\n",
      "Epoch 124/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9818 - val_loss: 0.0469 - val_accuracy: 0.9807\n",
      "Epoch 125/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9832 - val_loss: 0.0479 - val_accuracy: 0.9807\n",
      "Epoch 126/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9832 - val_loss: 0.0479 - val_accuracy: 0.9807\n",
      "Epoch 127/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.9821 - val_loss: 0.0461 - val_accuracy: 0.9788\n",
      "Epoch 128/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9832 - val_loss: 0.0487 - val_accuracy: 0.9807\n",
      "Epoch 129/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9832 - val_loss: 0.0464 - val_accuracy: 0.9807\n",
      "Epoch 130/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9827 - val_loss: 0.0511 - val_accuracy: 0.9752\n",
      "Epoch 131/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0380 - accuracy: 0.9825 - val_loss: 0.0453 - val_accuracy: 0.9807\n",
      "Epoch 132/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9832 - val_loss: 0.0473 - val_accuracy: 0.9807\n",
      "Epoch 133/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9832 - val_loss: 0.0462 - val_accuracy: 0.9807\n",
      "Epoch 134/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9832 - val_loss: 0.0471 - val_accuracy: 0.9807\n",
      "Epoch 135/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9823 - val_loss: 0.0481 - val_accuracy: 0.9807\n",
      "Epoch 136/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9823 - val_loss: 0.0464 - val_accuracy: 0.9807\n",
      "Epoch 137/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9818 - val_loss: 0.0458 - val_accuracy: 0.9807\n",
      "Epoch 138/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9832 - val_loss: 0.0485 - val_accuracy: 0.9752\n",
      "Epoch 139/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9825 - val_loss: 0.0457 - val_accuracy: 0.9788\n",
      "Epoch 140/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9811 - val_loss: 0.0452 - val_accuracy: 0.9807\n",
      "Epoch 141/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9832 - val_loss: 0.0465 - val_accuracy: 0.9807\n",
      "Epoch 142/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.9816 - val_loss: 0.0440 - val_accuracy: 0.9788\n",
      "Epoch 143/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9837 - val_loss: 0.0454 - val_accuracy: 0.9807\n",
      "Epoch 144/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9832 - val_loss: 0.0457 - val_accuracy: 0.9807\n",
      "Epoch 145/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.9832 - val_loss: 0.0462 - val_accuracy: 0.9807\n",
      "Epoch 146/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9821 - val_loss: 0.0447 - val_accuracy: 0.9807\n",
      "Epoch 147/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9830 - val_loss: 0.0464 - val_accuracy: 0.9807\n",
      "Epoch 148/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9832 - val_loss: 0.0446 - val_accuracy: 0.9807\n",
      "Epoch 149/150\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9832 - val_loss: 0.0460 - val_accuracy: 0.9807\n",
      "Epoch 150/150\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9818 - val_loss: 0.0449 - val_accuracy: 0.9807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c790c27730>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 256, epochs = 150, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b60e7213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0449 - accuracy: 0.9807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04491296783089638, 0.9806807637214661]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe36c8",
   "metadata": {},
   "source": [
    "# Categorical Cross Entropy\n",
    "When we have multi class classification, we can't use binary cross entropy because binary cross entropy iclude only 2 classes. We use categorical cross entropy formulti class classification and there is no\n",
    " difference in the formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e82502d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"CCE2.jpg\" width=\"600\" height=\"150\" align=\"center\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html1 = '<img src=\"CCE2.jpg\" width=\"600\" height=\"150\" align=\"center\"/>'\n",
    "HTML(html1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e485d2",
   "metadata": {},
   "source": [
    "Like binary cross entropy, P is the predicted probability distribution and t is true probability distribution in categorical term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d7152a",
   "metadata": {},
   "source": [
    "## Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35ba6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import MaxPooling2D , Conv2D, Flatten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221a6e16",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e065347",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_2, y_train_2), (x_valid_2, y_valid_2) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5024799",
   "metadata": {},
   "source": [
    "## Anylyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46be155b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_2.shape, y_train_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca2921f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70414992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c790f5f1f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"253.574062pt\" height=\"251.453783pt\" viewBox=\"0 0 253.574062 251.453783\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-04-01T16:24:25.066748</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.0, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 251.453783 \nL 253.574062 251.453783 \nL 253.574062 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 28.934063 224.69394 \nL 246.374063 224.69394 \nL 246.374063 7.25394 \nL 28.934063 7.25394 \nz\n\" style=\"fill: #eaeaf2\"/>\n   </g>\n   <g clip-path=\"url(#pb36dc8433a)\">\n    <image xlink:href=\"data:image/png;base64,\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\" id=\"imagef7285a000d\" transform=\"scale(1 -1)translate(0 -218)\" x=\"28.934063\" y=\"-6.69394\" width=\"218\" height=\"218\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 32.81692 224.69394 \nL 32.81692 7.25394 \n\" clip-path=\"url(#pb36dc8433a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g style=\"fill: #262626\" transform=\"translate(29.758404 242.067533)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-30\" d=\"M 266 2259 \nQ 266 3072 433 3567 \nQ 600 4063 929 4331 \nQ 1259 4600 1759 4600 \nQ 2128 4600 2406 4451 \nQ 2684 4303 2865 4023 \nQ 3047 3744 3150 3342 \nQ 3253 2941 3253 2259 \nQ 3253 1453 3087 958 \nQ 2922 463 2592 192 \nQ 2263 -78 1759 -78 \nQ 1097 -78 719 397 \nQ 266 969 266 2259 \nz\nM 844 2259 \nQ 844 1131 1108 757 \nQ 1372 384 1759 384 \nQ 2147 384 2411 759 \nQ 2675 1134 2675 2259 \nQ 2675 3391 2411 3762 \nQ 2147 4134 1753 4134 \nQ 1366 4134 1134 3806 \nQ 844 3388 844 2259 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <path d=\"M 71.645491 224.69394 \nL 71.645491 7.25394 \n\" clip-path=\"url(#pb36dc8433a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g style=\"fill: #262626\" transform=\"translate(68.586975 242.067533)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-35\" d=\"M 266 1200 \nL 856 1250 \nQ 922 819 1161 601 \nQ 1400 384 1738 384 \nQ 2144 384 2425 690 \nQ 2706 997 2706 1503 \nQ 2706 1984 2436 2262 \nQ 2166 2541 1728 2541 \nQ 1456 2541 1237 2417 \nQ 1019 2294 894 2097 \nL 366 2166 \nL 809 4519 \nL 3088 4519 \nL 3088 3981 \nL 1259 3981 \nL 1013 2750 \nQ 1425 3038 1878 3038 \nQ 2478 3038 2890 2622 \nQ 3303 2206 3303 1553 \nQ 3303 931 2941 478 \nQ 2500 -78 1738 -78 \nQ 1113 -78 717 272 \nQ 322 622 266 1200 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <path d=\"M 110.474063 224.69394 \nL 110.474063 7.25394 \n\" clip-path=\"url(#pb36dc8433a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <g style=\"fill: #262626\" transform=\"translate(104.357031 242.067533)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-31\" d=\"M 2384 0 \nL 1822 0 \nL 1822 3584 \nQ 1619 3391 1289 3197 \nQ 959 3003 697 2906 \nL 697 3450 \nQ 1169 3672 1522 3987 \nQ 1875 4303 2022 4600 \nL 2384 4600 \nL 2384 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <path d=\"M 149.302634 224.69394 \nL 149.302634 7.25394 \n\" clip-path=\"url(#pb36dc8433a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g style=\"fill: #262626\" transform=\"translate(143.185603 242.067533)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-35\" x=\"55.615234\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <path d=\"M 188.131205 224.69394 \nL 188.131205 7.25394 \n\" clip-path=\"url(#pb36dc8433a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <g style=\"fill: #262626\" transform=\"translate(182.014174 242.067533)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-32\" d=\"M 3222 541 \nL 3222 0 \nL 194 0 \nQ 188 203 259 391 \nQ 375 700 629 1000 \nQ 884 1300 1366 1694 \nQ 2113 2306 2375 2664 \nQ 2638 3022 2638 3341 \nQ 2638 3675 2398 3904 \nQ 2159 4134 1775 4134 \nQ 1369 4134 1125 3890 \nQ 881 3647 878 3216 \nL 300 3275 \nQ 359 3922 746 4261 \nQ 1134 4600 1788 4600 \nQ 2447 4600 2831 4234 \nQ 3216 3869 3216 3328 \nQ 3216 3053 3103 2787 \nQ 2991 2522 2730 2228 \nQ 2469 1934 1863 1422 \nQ 1356 997 1212 845 \nQ 1069 694 975 541 \nL 3222 541 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-32\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <path d=\"M 226.959777 224.69394 \nL 226.959777 7.25394 \n\" clip-path=\"url(#pb36dc8433a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g style=\"fill: #262626\" transform=\"translate(220.842746 242.067533)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-32\"/>\n       <use xlink:href=\"#ArialMT-35\" x=\"55.615234\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <path d=\"M 28.934063 11.136797 \nL 246.374063 11.136797 \n\" clip-path=\"url(#pb36dc8433a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g style=\"fill: #262626\" transform=\"translate(13.317031 15.073594)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <path d=\"M 28.934063 49.965368 \nL 246.374063 49.965368 \n\" clip-path=\"url(#pb36dc8433a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g style=\"fill: #262626\" transform=\"translate(13.317031 53.902165)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <path d=\"M 28.934063 88.79394 \nL 246.374063 88.79394 \n\" clip-path=\"url(#pb36dc8433a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 92.730737)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <path d=\"M 28.934063 127.622511 \nL 246.374063 127.622511 \n\" clip-path=\"url(#pb36dc8433a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 131.559308)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-35\" x=\"55.615234\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <path d=\"M 28.934063 166.451083 \nL 246.374063 166.451083 \n\" clip-path=\"url(#pb36dc8433a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 170.387879)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-32\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <path d=\"M 28.934063 205.279654 \nL 246.374063 205.279654 \n\" clip-path=\"url(#pb36dc8433a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 209.216451)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-32\"/>\n       <use xlink:href=\"#ArialMT-35\" x=\"55.615234\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 28.934063 224.69394 \nL 28.934063 7.25394 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 246.374063 224.69394 \nL 246.374063 7.25394 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 28.934063 224.69394 \nL 246.374063 224.69394 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 28.934063 7.25394 \nL 246.374063 7.25394 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pb36dc8433a\">\n   <rect x=\"28.934063\" y=\"7.25394\" width=\"217.44\" height=\"217.44\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train_2[0],cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017a45f",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88b51acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2_c = x_train_2.reshape(60000, 784).astype('float32')\n",
    "x_valid_2_c = x_valid_2.reshape(10000, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acab5248",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2_c /= 255\n",
    "x_valid_2_c /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b518067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
       "       0.5921569 , 0.23529412, 0.14117648, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.94509804, 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "       0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.6666667 ,\n",
       "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.2627451 , 0.44705883,\n",
       "       0.28235295, 0.44705883, 0.6392157 , 0.8901961 , 0.99607843,\n",
       "       0.88235295, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
       "       0.8980392 , 0.99607843, 0.99607843, 0.54901963, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "       0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "       0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.3254902 , 0.99215686, 0.81960785, 0.07058824,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.08627451, 0.9137255 ,\n",
       "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.5058824 , 0.99607843, 0.93333334, 0.17254902,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.23137255, 0.9764706 ,\n",
       "       0.99607843, 0.24313726, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03529412, 0.8039216 ,\n",
       "       0.972549  , 0.22745098, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.49411765, 0.99607843, 0.7137255 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.29411766, 0.9843137 ,\n",
       "       0.9411765 , 0.22352941, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.07450981, 0.8666667 , 0.99607843, 0.6509804 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "       0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14901961, 0.99607843, 0.99607843, 0.3019608 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.12156863, 0.8784314 , 0.99607843,\n",
       "       0.4509804 , 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.52156866, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.23921569, 0.9490196 , 0.99607843,\n",
       "       0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
       "       0.8117647 , 0.07058824, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid_2_c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc8a19d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "y_train_2_c = to_categorical(y_train_2, n_classes)\n",
    "y_valid_2_c = to_categorical(y_valid_2, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6029223e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_2_c[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e2fc90",
   "metadata": {},
   "source": [
    "## Deisgn Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "112555dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(64, activation='sigmoid', input_shape=(784,)))\n",
    "model_2.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09172600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef811415",
   "metadata": {},
   "source": [
    "## Configuration & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdcd5a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmagb\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3eb1202a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "469/469 [==============================] - 4s 2ms/step - loss: 2.0800 - accuracy: 0.4772 - val_loss: 1.8487 - val_accuracy: 0.6636\n",
      "Epoch 2/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.6621 - accuracy: 0.7090 - val_loss: 1.4679 - val_accuracy: 0.7465\n",
      "Epoch 3/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.3310 - accuracy: 0.7668 - val_loss: 1.1813 - val_accuracy: 0.7887\n",
      "Epoch 4/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.0915 - accuracy: 0.7991 - val_loss: 0.9816 - val_accuracy: 0.8142\n",
      "Epoch 5/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.9261 - accuracy: 0.8215 - val_loss: 0.8445 - val_accuracy: 0.8312\n",
      "Epoch 6/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.8110 - accuracy: 0.8357 - val_loss: 0.7475 - val_accuracy: 0.8477\n",
      "Epoch 7/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.7281 - accuracy: 0.8458 - val_loss: 0.6767 - val_accuracy: 0.8556\n",
      "Epoch 8/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.6663 - accuracy: 0.8541 - val_loss: 0.6229 - val_accuracy: 0.8651\n",
      "Epoch 9/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.6185 - accuracy: 0.8602 - val_loss: 0.5806 - val_accuracy: 0.8712\n",
      "Epoch 10/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5806 - accuracy: 0.8657 - val_loss: 0.5468 - val_accuracy: 0.8760\n",
      "Epoch 11/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5498 - accuracy: 0.8699 - val_loss: 0.5193 - val_accuracy: 0.8799\n",
      "Epoch 12/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.5243 - accuracy: 0.8737 - val_loss: 0.4962 - val_accuracy: 0.8829\n",
      "Epoch 13/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5027 - accuracy: 0.8770 - val_loss: 0.4766 - val_accuracy: 0.8856\n",
      "Epoch 14/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4843 - accuracy: 0.8800 - val_loss: 0.4600 - val_accuracy: 0.8874\n",
      "Epoch 15/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4683 - accuracy: 0.8828 - val_loss: 0.4451 - val_accuracy: 0.8902\n",
      "Epoch 16/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4544 - accuracy: 0.8848 - val_loss: 0.4324 - val_accuracy: 0.8927\n",
      "Epoch 17/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4421 - accuracy: 0.8867 - val_loss: 0.4212 - val_accuracy: 0.8944\n",
      "Epoch 18/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4312 - accuracy: 0.8890 - val_loss: 0.4109 - val_accuracy: 0.8952\n",
      "Epoch 19/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4213 - accuracy: 0.8906 - val_loss: 0.4018 - val_accuracy: 0.8969\n",
      "Epoch 20/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4125 - accuracy: 0.8921 - val_loss: 0.3937 - val_accuracy: 0.8978\n",
      "Epoch 21/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4045 - accuracy: 0.8935 - val_loss: 0.3867 - val_accuracy: 0.8983\n",
      "Epoch 22/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3972 - accuracy: 0.8948 - val_loss: 0.3799 - val_accuracy: 0.8996\n",
      "Epoch 23/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3904 - accuracy: 0.8965 - val_loss: 0.3734 - val_accuracy: 0.9000\n",
      "Epoch 24/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3843 - accuracy: 0.8972 - val_loss: 0.3679 - val_accuracy: 0.9016\n",
      "Epoch 25/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3785 - accuracy: 0.8985 - val_loss: 0.3624 - val_accuracy: 0.9024\n",
      "Epoch 26/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3732 - accuracy: 0.8997 - val_loss: 0.3575 - val_accuracy: 0.9031\n",
      "Epoch 27/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3682 - accuracy: 0.9009 - val_loss: 0.3528 - val_accuracy: 0.9044\n",
      "Epoch 28/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.9015 - val_loss: 0.3485 - val_accuracy: 0.9052\n",
      "Epoch 29/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.3592 - accuracy: 0.9024 - val_loss: 0.3444 - val_accuracy: 0.9076\n",
      "Epoch 30/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3551 - accuracy: 0.9033 - val_loss: 0.3407 - val_accuracy: 0.9075\n",
      "Epoch 31/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3512 - accuracy: 0.9041 - val_loss: 0.3370 - val_accuracy: 0.9084\n",
      "Epoch 32/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3475 - accuracy: 0.9051 - val_loss: 0.3337 - val_accuracy: 0.9097\n",
      "Epoch 33/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3441 - accuracy: 0.9056 - val_loss: 0.3305 - val_accuracy: 0.9108\n",
      "Epoch 34/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3407 - accuracy: 0.9060 - val_loss: 0.3276 - val_accuracy: 0.9114\n",
      "Epoch 35/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3376 - accuracy: 0.9066 - val_loss: 0.3245 - val_accuracy: 0.9120\n",
      "Epoch 36/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.3346 - accuracy: 0.9072 - val_loss: 0.3219 - val_accuracy: 0.9126\n",
      "Epoch 37/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3317 - accuracy: 0.9079 - val_loss: 0.3192 - val_accuracy: 0.9130\n",
      "Epoch 38/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3289 - accuracy: 0.9086 - val_loss: 0.3168 - val_accuracy: 0.9134\n",
      "Epoch 39/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3263 - accuracy: 0.9092 - val_loss: 0.3142 - val_accuracy: 0.9146\n",
      "Epoch 40/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3237 - accuracy: 0.9094 - val_loss: 0.3120 - val_accuracy: 0.9146\n",
      "Epoch 41/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3213 - accuracy: 0.9103 - val_loss: 0.3096 - val_accuracy: 0.9147\n",
      "Epoch 42/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3189 - accuracy: 0.9111 - val_loss: 0.3076 - val_accuracy: 0.9162\n",
      "Epoch 43/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3166 - accuracy: 0.9118 - val_loss: 0.3055 - val_accuracy: 0.9161\n",
      "Epoch 44/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3144 - accuracy: 0.9122 - val_loss: 0.3034 - val_accuracy: 0.9171\n",
      "Epoch 45/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3123 - accuracy: 0.9127 - val_loss: 0.3016 - val_accuracy: 0.9169\n",
      "Epoch 46/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3102 - accuracy: 0.9132 - val_loss: 0.2997 - val_accuracy: 0.9169\n",
      "Epoch 47/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3082 - accuracy: 0.9137 - val_loss: 0.2977 - val_accuracy: 0.9171\n",
      "Epoch 48/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3062 - accuracy: 0.9143 - val_loss: 0.2961 - val_accuracy: 0.9183\n",
      "Epoch 49/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3043 - accuracy: 0.9147 - val_loss: 0.2942 - val_accuracy: 0.9185\n",
      "Epoch 50/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3025 - accuracy: 0.9150 - val_loss: 0.2925 - val_accuracy: 0.9189\n",
      "Epoch 51/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3007 - accuracy: 0.9157 - val_loss: 0.2909 - val_accuracy: 0.9190\n",
      "Epoch 52/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2989 - accuracy: 0.9160 - val_loss: 0.2894 - val_accuracy: 0.9194\n",
      "Epoch 53/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2972 - accuracy: 0.9168 - val_loss: 0.2878 - val_accuracy: 0.9206\n",
      "Epoch 54/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2955 - accuracy: 0.9167 - val_loss: 0.2864 - val_accuracy: 0.9207\n",
      "Epoch 55/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2938 - accuracy: 0.9174 - val_loss: 0.2849 - val_accuracy: 0.9209\n",
      "Epoch 56/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2922 - accuracy: 0.9180 - val_loss: 0.2836 - val_accuracy: 0.9212\n",
      "Epoch 57/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2907 - accuracy: 0.9181 - val_loss: 0.2819 - val_accuracy: 0.9219\n",
      "Epoch 58/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2891 - accuracy: 0.9184 - val_loss: 0.2807 - val_accuracy: 0.9218\n",
      "Epoch 59/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2876 - accuracy: 0.9189 - val_loss: 0.2792 - val_accuracy: 0.9225\n",
      "Epoch 60/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2861 - accuracy: 0.9194 - val_loss: 0.2782 - val_accuracy: 0.9229\n",
      "Epoch 61/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2847 - accuracy: 0.9197 - val_loss: 0.2766 - val_accuracy: 0.9229\n",
      "Epoch 62/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2832 - accuracy: 0.9201 - val_loss: 0.2754 - val_accuracy: 0.9231\n",
      "Epoch 63/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2818 - accuracy: 0.9203 - val_loss: 0.2741 - val_accuracy: 0.9234\n",
      "Epoch 64/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2804 - accuracy: 0.9205 - val_loss: 0.2728 - val_accuracy: 0.9236\n",
      "Epoch 65/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2791 - accuracy: 0.9211 - val_loss: 0.2718 - val_accuracy: 0.9236\n",
      "Epoch 66/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2777 - accuracy: 0.9212 - val_loss: 0.2705 - val_accuracy: 0.9240\n",
      "Epoch 67/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2764 - accuracy: 0.9216 - val_loss: 0.2693 - val_accuracy: 0.9247\n",
      "Epoch 68/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2751 - accuracy: 0.9219 - val_loss: 0.2682 - val_accuracy: 0.9253\n",
      "Epoch 69/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2738 - accuracy: 0.9224 - val_loss: 0.2672 - val_accuracy: 0.9250\n",
      "Epoch 70/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2725 - accuracy: 0.9225 - val_loss: 0.2659 - val_accuracy: 0.9252\n",
      "Epoch 71/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2713 - accuracy: 0.9228 - val_loss: 0.2647 - val_accuracy: 0.9261\n",
      "Epoch 72/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2701 - accuracy: 0.9231 - val_loss: 0.2636 - val_accuracy: 0.9259\n",
      "Epoch 73/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2689 - accuracy: 0.9233 - val_loss: 0.2627 - val_accuracy: 0.9264\n",
      "Epoch 74/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2677 - accuracy: 0.9238 - val_loss: 0.2615 - val_accuracy: 0.9264\n",
      "Epoch 75/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2665 - accuracy: 0.9239 - val_loss: 0.2606 - val_accuracy: 0.9267\n",
      "Epoch 76/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2653 - accuracy: 0.9244 - val_loss: 0.2596 - val_accuracy: 0.9267\n",
      "Epoch 77/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2642 - accuracy: 0.9248 - val_loss: 0.2583 - val_accuracy: 0.9274\n",
      "Epoch 78/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2630 - accuracy: 0.9253 - val_loss: 0.2573 - val_accuracy: 0.9276\n",
      "Epoch 79/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2619 - accuracy: 0.9252 - val_loss: 0.2565 - val_accuracy: 0.9275\n",
      "Epoch 80/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2608 - accuracy: 0.9258 - val_loss: 0.2555 - val_accuracy: 0.9284\n",
      "Epoch 81/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2597 - accuracy: 0.9258 - val_loss: 0.2545 - val_accuracy: 0.9282\n",
      "Epoch 82/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2586 - accuracy: 0.9264 - val_loss: 0.2533 - val_accuracy: 0.9285\n",
      "Epoch 83/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2575 - accuracy: 0.9268 - val_loss: 0.2525 - val_accuracy: 0.9283\n",
      "Epoch 84/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2564 - accuracy: 0.9267 - val_loss: 0.2515 - val_accuracy: 0.9287\n",
      "Epoch 85/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2554 - accuracy: 0.9274 - val_loss: 0.2505 - val_accuracy: 0.9288\n",
      "Epoch 86/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2544 - accuracy: 0.9277 - val_loss: 0.2495 - val_accuracy: 0.9291\n",
      "Epoch 87/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2533 - accuracy: 0.9278 - val_loss: 0.2488 - val_accuracy: 0.9286\n",
      "Epoch 88/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2523 - accuracy: 0.9280 - val_loss: 0.2479 - val_accuracy: 0.9296\n",
      "Epoch 89/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2513 - accuracy: 0.9283 - val_loss: 0.2467 - val_accuracy: 0.9297\n",
      "Epoch 90/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2503 - accuracy: 0.9285 - val_loss: 0.2458 - val_accuracy: 0.9298\n",
      "Epoch 91/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2493 - accuracy: 0.9292 - val_loss: 0.2451 - val_accuracy: 0.9306\n",
      "Epoch 92/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2483 - accuracy: 0.9294 - val_loss: 0.2442 - val_accuracy: 0.9303\n",
      "Epoch 93/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2474 - accuracy: 0.9297 - val_loss: 0.2434 - val_accuracy: 0.9311\n",
      "Epoch 94/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2464 - accuracy: 0.9302 - val_loss: 0.2425 - val_accuracy: 0.9312\n",
      "Epoch 95/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2454 - accuracy: 0.9304 - val_loss: 0.2417 - val_accuracy: 0.9312\n",
      "Epoch 96/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2445 - accuracy: 0.9309 - val_loss: 0.2408 - val_accuracy: 0.9315\n",
      "Epoch 97/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2435 - accuracy: 0.9311 - val_loss: 0.2400 - val_accuracy: 0.9315\n",
      "Epoch 98/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2426 - accuracy: 0.9313 - val_loss: 0.2392 - val_accuracy: 0.9318\n",
      "Epoch 99/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2417 - accuracy: 0.9316 - val_loss: 0.2383 - val_accuracy: 0.9322\n",
      "Epoch 100/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2408 - accuracy: 0.9319 - val_loss: 0.2376 - val_accuracy: 0.9320\n",
      "Epoch 101/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2399 - accuracy: 0.9323 - val_loss: 0.2366 - val_accuracy: 0.9324\n",
      "Epoch 102/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2390 - accuracy: 0.9324 - val_loss: 0.2358 - val_accuracy: 0.9333\n",
      "Epoch 103/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2381 - accuracy: 0.9327 - val_loss: 0.2353 - val_accuracy: 0.9334\n",
      "Epoch 104/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2372 - accuracy: 0.9332 - val_loss: 0.2345 - val_accuracy: 0.9334\n",
      "Epoch 105/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2363 - accuracy: 0.9330 - val_loss: 0.2335 - val_accuracy: 0.9339\n",
      "Epoch 106/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2355 - accuracy: 0.9335 - val_loss: 0.2327 - val_accuracy: 0.9344\n",
      "Epoch 107/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2346 - accuracy: 0.9337 - val_loss: 0.2320 - val_accuracy: 0.9346\n",
      "Epoch 108/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2338 - accuracy: 0.9340 - val_loss: 0.2312 - val_accuracy: 0.9351\n",
      "Epoch 109/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2329 - accuracy: 0.9342 - val_loss: 0.2305 - val_accuracy: 0.9350\n",
      "Epoch 110/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2321 - accuracy: 0.9345 - val_loss: 0.2296 - val_accuracy: 0.9355\n",
      "Epoch 111/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2313 - accuracy: 0.9348 - val_loss: 0.2288 - val_accuracy: 0.9357\n",
      "Epoch 112/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2305 - accuracy: 0.9348 - val_loss: 0.2281 - val_accuracy: 0.9359\n",
      "Epoch 113/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2296 - accuracy: 0.9353 - val_loss: 0.2274 - val_accuracy: 0.9364\n",
      "Epoch 114/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2288 - accuracy: 0.9356 - val_loss: 0.2268 - val_accuracy: 0.9363\n",
      "Epoch 115/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2280 - accuracy: 0.9357 - val_loss: 0.2262 - val_accuracy: 0.9359\n",
      "Epoch 116/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2272 - accuracy: 0.9359 - val_loss: 0.2253 - val_accuracy: 0.9366\n",
      "Epoch 117/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2265 - accuracy: 0.9363 - val_loss: 0.2245 - val_accuracy: 0.9367\n",
      "Epoch 118/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2257 - accuracy: 0.9364 - val_loss: 0.2239 - val_accuracy: 0.9367\n",
      "Epoch 119/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2249 - accuracy: 0.9369 - val_loss: 0.2232 - val_accuracy: 0.9368\n",
      "Epoch 120/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2241 - accuracy: 0.9369 - val_loss: 0.2225 - val_accuracy: 0.9369\n",
      "Epoch 121/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2234 - accuracy: 0.9373 - val_loss: 0.2219 - val_accuracy: 0.9370\n",
      "Epoch 122/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2226 - accuracy: 0.9372 - val_loss: 0.2211 - val_accuracy: 0.9372\n",
      "Epoch 123/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2219 - accuracy: 0.9375 - val_loss: 0.2205 - val_accuracy: 0.9371\n",
      "Epoch 124/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2211 - accuracy: 0.9379 - val_loss: 0.2197 - val_accuracy: 0.9374\n",
      "Epoch 125/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2204 - accuracy: 0.9381 - val_loss: 0.2191 - val_accuracy: 0.9376\n",
      "Epoch 126/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2196 - accuracy: 0.9384 - val_loss: 0.2184 - val_accuracy: 0.9377\n",
      "Epoch 127/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2189 - accuracy: 0.9386 - val_loss: 0.2178 - val_accuracy: 0.9383\n",
      "Epoch 128/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2182 - accuracy: 0.9386 - val_loss: 0.2171 - val_accuracy: 0.9382\n",
      "Epoch 129/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2175 - accuracy: 0.9389 - val_loss: 0.2164 - val_accuracy: 0.9385\n",
      "Epoch 130/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2168 - accuracy: 0.9390 - val_loss: 0.2157 - val_accuracy: 0.9381\n",
      "Epoch 131/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2161 - accuracy: 0.9393 - val_loss: 0.2153 - val_accuracy: 0.9388\n",
      "Epoch 132/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2154 - accuracy: 0.9396 - val_loss: 0.2145 - val_accuracy: 0.9378\n",
      "Epoch 133/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2147 - accuracy: 0.9394 - val_loss: 0.2141 - val_accuracy: 0.9386\n",
      "Epoch 134/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2140 - accuracy: 0.9400 - val_loss: 0.2133 - val_accuracy: 0.9385\n",
      "Epoch 135/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2133 - accuracy: 0.9401 - val_loss: 0.2128 - val_accuracy: 0.9386\n",
      "Epoch 136/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2126 - accuracy: 0.9403 - val_loss: 0.2121 - val_accuracy: 0.9391\n",
      "Epoch 137/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2119 - accuracy: 0.9404 - val_loss: 0.2117 - val_accuracy: 0.9388\n",
      "Epoch 138/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2113 - accuracy: 0.9407 - val_loss: 0.2108 - val_accuracy: 0.9389\n",
      "Epoch 139/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2106 - accuracy: 0.9407 - val_loss: 0.2103 - val_accuracy: 0.9391\n",
      "Epoch 140/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2100 - accuracy: 0.9409 - val_loss: 0.2096 - val_accuracy: 0.9395\n",
      "Epoch 141/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2093 - accuracy: 0.9411 - val_loss: 0.2090 - val_accuracy: 0.9395\n",
      "Epoch 142/150\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2087 - accuracy: 0.9412 - val_loss: 0.2084 - val_accuracy: 0.9393\n",
      "Epoch 143/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2080 - accuracy: 0.9416 - val_loss: 0.2079 - val_accuracy: 0.9400\n",
      "Epoch 144/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2074 - accuracy: 0.9419 - val_loss: 0.2073 - val_accuracy: 0.9397\n",
      "Epoch 145/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2068 - accuracy: 0.9418 - val_loss: 0.2067 - val_accuracy: 0.9399\n",
      "Epoch 146/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2061 - accuracy: 0.9420 - val_loss: 0.2062 - val_accuracy: 0.9400\n",
      "Epoch 147/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2055 - accuracy: 0.9420 - val_loss: 0.2056 - val_accuracy: 0.9399\n",
      "Epoch 148/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2048 - accuracy: 0.9423 - val_loss: 0.2051 - val_accuracy: 0.9398\n",
      "Epoch 149/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2042 - accuracy: 0.9425 - val_loss: 0.2044 - val_accuracy: 0.9403\n",
      "Epoch 150/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2036 - accuracy: 0.9425 - val_loss: 0.2039 - val_accuracy: 0.9403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c790f5fd90>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(x_train_2_c, y_train_2_c, batch_size=128, epochs=150, verbose=1, validation_data=(x_valid_2_c, y_valid_2_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2cc394d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2039 - accuracy: 0.9403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20392625033855438, 0.9402999877929688]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(x_valid_2_c,y_valid_2_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1b2390",
   "metadata": {},
   "source": [
    "#  Sparse Categorical Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0ccea1",
   "metadata": {},
   "source": [
    "The sparse categorical cross entropy is much like categorical cross entorpy with a slight difference, in categorical cross entropy the true distribution is multiplied to logarithm of the predicted distribution, and because the true distribution vector is all zero except one index it returns only one logarithmic term that has the same index in the true distribution but in the sparse categorical cross entropy there is no true disturbution and the only term is logarithm of maximum value of prediction.\n",
    "\n",
    "Let's clear it by example:\n",
    "\n",
    "Consider a classification problem with 5 categories (or classes). In the case of categorical cross entropy, the one-hot target may be [0, 1, 0, 0, 0] (which means second class) and the model may predict [.2, .5, .1, .1, .1] (probably right), then we multiply the first vector to logarithm of second vector and because all of indexes of the first vector is zero except the second one, we can multilpy the second index of each vector only so we have 1 * log(.5)\n",
    "In the case of sparse categorical cross entropy, the target index is the maximum value of the second vector and that is [.5] with 2nd index, so our equation give us the log(0.5) with index of 1 (because the 2nd value of first vector is 1) as a solution.\n",
    "\n",
    "Consider now a classification problem with 3 classes. In the case of categorical cross entropy, the one-hot target might be [0, 0, 1] and the model may predict [.5, .1, .4] (probably inaccurate, given that it gives more probability to the first class) so we multiply the third value of each vector only and it give us 1 * log(0.4)\n",
    "But in the case of sparse categorical cross entropy, the target index is the maximum value of the second vector and that is [.5] with 3rd index, so our equation give us the log(0.5) with index of 0 (because the 3rd value of first vector is 0) as a solution.\n",
    "\n",
    "### Many categorical models produce sparse categorical cross entropy output because you save space, but lose A LOT of information.\n",
    "\n",
    "There are a number of situations to use sparse categorical cross entropy, including:\n",
    "1. when your classes are mutually exclusive, i.e. you don’t care at all about other close-enough predictions\n",
    "2. the number of categories is large to the prediction output becomes overwhelming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e2fc90",
   "metadata": {},
   "source": [
    "## Deisgn Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "112555dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Dense(64, activation='sigmoid', input_shape=(784,)))\n",
    "model_3.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09172600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef811415",
   "metadata": {},
   "source": [
    "## Configuration & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fdcd5a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(loss='sparse_categorical_crossentropy', optimizer=SGD(lr=0.001), metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c8f3130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6], dtype=uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_2[0:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3eb1202a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "469/469 [==============================] - 3s 2ms/step - loss: 2.4044 - sparse_categorical_accuracy: 0.0972 - val_loss: 2.3089 - val_sparse_categorical_accuracy: 0.1124\n",
      "Epoch 2/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.2671 - sparse_categorical_accuracy: 0.1787 - val_loss: 2.2270 - val_sparse_categorical_accuracy: 0.2983\n",
      "Epoch 3/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.2021 - sparse_categorical_accuracy: 0.3576 - val_loss: 2.1709 - val_sparse_categorical_accuracy: 0.4211\n",
      "Epoch 4/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.1502 - sparse_categorical_accuracy: 0.4493 - val_loss: 2.1205 - val_sparse_categorical_accuracy: 0.5182\n",
      "Epoch 5/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 2.1015 - sparse_categorical_accuracy: 0.5304 - val_loss: 2.0721 - val_sparse_categorical_accuracy: 0.5785\n",
      "Epoch 6/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 2.0543 - sparse_categorical_accuracy: 0.5777 - val_loss: 2.0248 - val_sparse_categorical_accuracy: 0.6155\n",
      "Epoch 7/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 2.0082 - sparse_categorical_accuracy: 0.6128 - val_loss: 1.9784 - val_sparse_categorical_accuracy: 0.6402\n",
      "Epoch 8/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.9628 - sparse_categorical_accuracy: 0.6351 - val_loss: 1.9329 - val_sparse_categorical_accuracy: 0.6611\n",
      "Epoch 9/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.9183 - sparse_categorical_accuracy: 0.6511 - val_loss: 1.8882 - val_sparse_categorical_accuracy: 0.6758\n",
      "Epoch 10/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.8745 - sparse_categorical_accuracy: 0.6664 - val_loss: 1.8443 - val_sparse_categorical_accuracy: 0.6858\n",
      "Epoch 11/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.8315 - sparse_categorical_accuracy: 0.6763 - val_loss: 1.8011 - val_sparse_categorical_accuracy: 0.6953\n",
      "Epoch 12/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.7893 - sparse_categorical_accuracy: 0.6842 - val_loss: 1.7587 - val_sparse_categorical_accuracy: 0.7035\n",
      "Epoch 13/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.7478 - sparse_categorical_accuracy: 0.6925 - val_loss: 1.7171 - val_sparse_categorical_accuracy: 0.7120\n",
      "Epoch 14/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.7072 - sparse_categorical_accuracy: 0.6998 - val_loss: 1.6764 - val_sparse_categorical_accuracy: 0.7181\n",
      "Epoch 15/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.6674 - sparse_categorical_accuracy: 0.7057 - val_loss: 1.6366 - val_sparse_categorical_accuracy: 0.7243\n",
      "Epoch 16/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.6284 - sparse_categorical_accuracy: 0.7135 - val_loss: 1.5977 - val_sparse_categorical_accuracy: 0.7304\n",
      "Epoch 17/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.5904 - sparse_categorical_accuracy: 0.7198 - val_loss: 1.5598 - val_sparse_categorical_accuracy: 0.7379\n",
      "Epoch 18/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.5534 - sparse_categorical_accuracy: 0.7260 - val_loss: 1.5228 - val_sparse_categorical_accuracy: 0.7421\n",
      "Epoch 19/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.5173 - sparse_categorical_accuracy: 0.7314 - val_loss: 1.4869 - val_sparse_categorical_accuracy: 0.7479\n",
      "Epoch 20/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.4823 - sparse_categorical_accuracy: 0.7374 - val_loss: 1.4520 - val_sparse_categorical_accuracy: 0.7534\n",
      "Epoch 21/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.4483 - sparse_categorical_accuracy: 0.7422 - val_loss: 1.4182 - val_sparse_categorical_accuracy: 0.7590\n",
      "Epoch 22/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.4154 - sparse_categorical_accuracy: 0.7471 - val_loss: 1.3855 - val_sparse_categorical_accuracy: 0.7637\n",
      "Epoch 23/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.3835 - sparse_categorical_accuracy: 0.7518 - val_loss: 1.3538 - val_sparse_categorical_accuracy: 0.7680\n",
      "Epoch 24/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.3527 - sparse_categorical_accuracy: 0.7567 - val_loss: 1.3233 - val_sparse_categorical_accuracy: 0.7725\n",
      "Epoch 25/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.3229 - sparse_categorical_accuracy: 0.7620 - val_loss: 1.2938 - val_sparse_categorical_accuracy: 0.7777\n",
      "Epoch 26/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.2942 - sparse_categorical_accuracy: 0.7662 - val_loss: 1.2654 - val_sparse_categorical_accuracy: 0.7818\n",
      "Epoch 27/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.2665 - sparse_categorical_accuracy: 0.7707 - val_loss: 1.2380 - val_sparse_categorical_accuracy: 0.7858\n",
      "Epoch 28/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.2399 - sparse_categorical_accuracy: 0.7746 - val_loss: 1.2116 - val_sparse_categorical_accuracy: 0.7904\n",
      "Epoch 29/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.2142 - sparse_categorical_accuracy: 0.7789 - val_loss: 1.1862 - val_sparse_categorical_accuracy: 0.7943\n",
      "Epoch 30/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.1895 - sparse_categorical_accuracy: 0.7828 - val_loss: 1.1618 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 31/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.1657 - sparse_categorical_accuracy: 0.7864 - val_loss: 1.1382 - val_sparse_categorical_accuracy: 0.8027\n",
      "Epoch 32/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.1429 - sparse_categorical_accuracy: 0.7905 - val_loss: 1.1157 - val_sparse_categorical_accuracy: 0.8053\n",
      "Epoch 33/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.1209 - sparse_categorical_accuracy: 0.7940 - val_loss: 1.0940 - val_sparse_categorical_accuracy: 0.8088\n",
      "Epoch 34/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.0998 - sparse_categorical_accuracy: 0.7965 - val_loss: 1.0731 - val_sparse_categorical_accuracy: 0.8118\n",
      "Epoch 35/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.0795 - sparse_categorical_accuracy: 0.8000 - val_loss: 1.0531 - val_sparse_categorical_accuracy: 0.8140\n",
      "Epoch 36/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.0600 - sparse_categorical_accuracy: 0.8022 - val_loss: 1.0338 - val_sparse_categorical_accuracy: 0.8153\n",
      "Epoch 37/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.0412 - sparse_categorical_accuracy: 0.8049 - val_loss: 1.0153 - val_sparse_categorical_accuracy: 0.8190\n",
      "Epoch 38/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.0232 - sparse_categorical_accuracy: 0.8081 - val_loss: 0.9975 - val_sparse_categorical_accuracy: 0.8211\n",
      "Epoch 39/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.0059 - sparse_categorical_accuracy: 0.8111 - val_loss: 0.9804 - val_sparse_categorical_accuracy: 0.8222\n",
      "Epoch 40/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.9892 - sparse_categorical_accuracy: 0.8134 - val_loss: 0.9639 - val_sparse_categorical_accuracy: 0.8245\n",
      "Epoch 41/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.9731 - sparse_categorical_accuracy: 0.8155 - val_loss: 0.9481 - val_sparse_categorical_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.9577 - sparse_categorical_accuracy: 0.8176 - val_loss: 0.9328 - val_sparse_categorical_accuracy: 0.8294\n",
      "Epoch 43/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.9428 - sparse_categorical_accuracy: 0.8201 - val_loss: 0.9182 - val_sparse_categorical_accuracy: 0.8311\n",
      "Epoch 44/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.9285 - sparse_categorical_accuracy: 0.8221 - val_loss: 0.9040 - val_sparse_categorical_accuracy: 0.8331\n",
      "Epoch 45/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.9147 - sparse_categorical_accuracy: 0.8242 - val_loss: 0.8904 - val_sparse_categorical_accuracy: 0.8342\n",
      "Epoch 46/150\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.9015 - sparse_categorical_accuracy: 0.8262 - val_loss: 0.8773 - val_sparse_categorical_accuracy: 0.8351\n",
      "Epoch 47/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.8887 - sparse_categorical_accuracy: 0.8278 - val_loss: 0.8647 - val_sparse_categorical_accuracy: 0.8368\n",
      "Epoch 48/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.8763 - sparse_categorical_accuracy: 0.8300 - val_loss: 0.8525 - val_sparse_categorical_accuracy: 0.8383\n",
      "Epoch 49/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.8644 - sparse_categorical_accuracy: 0.8315 - val_loss: 0.8407 - val_sparse_categorical_accuracy: 0.8397\n",
      "Epoch 50/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.8529 - sparse_categorical_accuracy: 0.8326 - val_loss: 0.8294 - val_sparse_categorical_accuracy: 0.8412\n",
      "Epoch 51/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.8419 - sparse_categorical_accuracy: 0.8342 - val_loss: 0.8184 - val_sparse_categorical_accuracy: 0.8423\n",
      "Epoch 52/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.8311 - sparse_categorical_accuracy: 0.8356 - val_loss: 0.8079 - val_sparse_categorical_accuracy: 0.8446\n",
      "Epoch 53/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.8208 - sparse_categorical_accuracy: 0.8370 - val_loss: 0.7977 - val_sparse_categorical_accuracy: 0.8463\n",
      "Epoch 54/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.8108 - sparse_categorical_accuracy: 0.8386 - val_loss: 0.7878 - val_sparse_categorical_accuracy: 0.8469\n",
      "Epoch 55/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.8011 - sparse_categorical_accuracy: 0.8399 - val_loss: 0.7782 - val_sparse_categorical_accuracy: 0.8477\n",
      "Epoch 56/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.7918 - sparse_categorical_accuracy: 0.8414 - val_loss: 0.7690 - val_sparse_categorical_accuracy: 0.8484\n",
      "Epoch 57/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.7827 - sparse_categorical_accuracy: 0.8426 - val_loss: 0.7600 - val_sparse_categorical_accuracy: 0.8497\n",
      "Epoch 58/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.7740 - sparse_categorical_accuracy: 0.8434 - val_loss: 0.7514 - val_sparse_categorical_accuracy: 0.8508\n",
      "Epoch 59/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.7655 - sparse_categorical_accuracy: 0.8450 - val_loss: 0.7430 - val_sparse_categorical_accuracy: 0.8517\n",
      "Epoch 60/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.7572 - sparse_categorical_accuracy: 0.8457 - val_loss: 0.7348 - val_sparse_categorical_accuracy: 0.8532\n",
      "Epoch 61/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.7493 - sparse_categorical_accuracy: 0.8468 - val_loss: 0.7270 - val_sparse_categorical_accuracy: 0.8542\n",
      "Epoch 62/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.7415 - sparse_categorical_accuracy: 0.8482 - val_loss: 0.7193 - val_sparse_categorical_accuracy: 0.8553\n",
      "Epoch 63/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.7340 - sparse_categorical_accuracy: 0.8487 - val_loss: 0.7119 - val_sparse_categorical_accuracy: 0.8560\n",
      "Epoch 64/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.7267 - sparse_categorical_accuracy: 0.8496 - val_loss: 0.7047 - val_sparse_categorical_accuracy: 0.8567\n",
      "Epoch 65/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.7197 - sparse_categorical_accuracy: 0.8503 - val_loss: 0.6977 - val_sparse_categorical_accuracy: 0.8578\n",
      "Epoch 66/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.7128 - sparse_categorical_accuracy: 0.8512 - val_loss: 0.6909 - val_sparse_categorical_accuracy: 0.8588\n",
      "Epoch 67/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.7061 - sparse_categorical_accuracy: 0.8519 - val_loss: 0.6843 - val_sparse_categorical_accuracy: 0.8595\n",
      "Epoch 68/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6996 - sparse_categorical_accuracy: 0.8526 - val_loss: 0.6779 - val_sparse_categorical_accuracy: 0.8605\n",
      "Epoch 69/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.6933 - sparse_categorical_accuracy: 0.8533 - val_loss: 0.6717 - val_sparse_categorical_accuracy: 0.8608\n",
      "Epoch 70/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.6872 - sparse_categorical_accuracy: 0.8540 - val_loss: 0.6656 - val_sparse_categorical_accuracy: 0.8620\n",
      "Epoch 71/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.6812 - sparse_categorical_accuracy: 0.8549 - val_loss: 0.6597 - val_sparse_categorical_accuracy: 0.8624\n",
      "Epoch 72/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.6754 - sparse_categorical_accuracy: 0.8555 - val_loss: 0.6540 - val_sparse_categorical_accuracy: 0.8632\n",
      "Epoch 73/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.6698 - sparse_categorical_accuracy: 0.8563 - val_loss: 0.6484 - val_sparse_categorical_accuracy: 0.8642\n",
      "Epoch 74/150\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.6643 - sparse_categorical_accuracy: 0.8567 - val_loss: 0.6429 - val_sparse_categorical_accuracy: 0.8654\n",
      "Epoch 75/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6589 - sparse_categorical_accuracy: 0.8574 - val_loss: 0.6376 - val_sparse_categorical_accuracy: 0.8662\n",
      "Epoch 76/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.6536 - sparse_categorical_accuracy: 0.8578 - val_loss: 0.6324 - val_sparse_categorical_accuracy: 0.8668\n",
      "Epoch 77/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6486 - sparse_categorical_accuracy: 0.8583 - val_loss: 0.6274 - val_sparse_categorical_accuracy: 0.8677\n",
      "Epoch 78/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6436 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.6225 - val_sparse_categorical_accuracy: 0.8683\n",
      "Epoch 79/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6387 - sparse_categorical_accuracy: 0.8597 - val_loss: 0.6177 - val_sparse_categorical_accuracy: 0.8691\n",
      "Epoch 80/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6340 - sparse_categorical_accuracy: 0.8601 - val_loss: 0.6130 - val_sparse_categorical_accuracy: 0.8700\n",
      "Epoch 81/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6294 - sparse_categorical_accuracy: 0.8609 - val_loss: 0.6084 - val_sparse_categorical_accuracy: 0.8706\n",
      "Epoch 82/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6248 - sparse_categorical_accuracy: 0.8617 - val_loss: 0.6040 - val_sparse_categorical_accuracy: 0.8709\n",
      "Epoch 83/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6204 - sparse_categorical_accuracy: 0.8626 - val_loss: 0.5996 - val_sparse_categorical_accuracy: 0.8717\n",
      "Epoch 84/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6161 - sparse_categorical_accuracy: 0.8630 - val_loss: 0.5953 - val_sparse_categorical_accuracy: 0.8727\n",
      "Epoch 85/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6119 - sparse_categorical_accuracy: 0.8632 - val_loss: 0.5912 - val_sparse_categorical_accuracy: 0.8732\n",
      "Epoch 86/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6078 - sparse_categorical_accuracy: 0.8637 - val_loss: 0.5871 - val_sparse_categorical_accuracy: 0.8737\n",
      "Epoch 87/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6038 - sparse_categorical_accuracy: 0.8642 - val_loss: 0.5832 - val_sparse_categorical_accuracy: 0.8747\n",
      "Epoch 88/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5999 - sparse_categorical_accuracy: 0.8649 - val_loss: 0.5793 - val_sparse_categorical_accuracy: 0.8757\n",
      "Epoch 89/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5960 - sparse_categorical_accuracy: 0.8653 - val_loss: 0.5755 - val_sparse_categorical_accuracy: 0.8761\n",
      "Epoch 90/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5923 - sparse_categorical_accuracy: 0.8657 - val_loss: 0.5718 - val_sparse_categorical_accuracy: 0.8766\n",
      "Epoch 91/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5886 - sparse_categorical_accuracy: 0.8664 - val_loss: 0.5681 - val_sparse_categorical_accuracy: 0.8769\n",
      "Epoch 92/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5850 - sparse_categorical_accuracy: 0.8667 - val_loss: 0.5646 - val_sparse_categorical_accuracy: 0.8771\n",
      "Epoch 93/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.5814 - sparse_categorical_accuracy: 0.8673 - val_loss: 0.5611 - val_sparse_categorical_accuracy: 0.8772\n",
      "Epoch 94/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5780 - sparse_categorical_accuracy: 0.8678 - val_loss: 0.5577 - val_sparse_categorical_accuracy: 0.8782\n",
      "Epoch 95/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.5746 - sparse_categorical_accuracy: 0.8682 - val_loss: 0.5543 - val_sparse_categorical_accuracy: 0.8785\n",
      "Epoch 96/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.5713 - sparse_categorical_accuracy: 0.8687 - val_loss: 0.5511 - val_sparse_categorical_accuracy: 0.8789\n",
      "Epoch 97/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.5680 - sparse_categorical_accuracy: 0.8692 - val_loss: 0.5479 - val_sparse_categorical_accuracy: 0.8792\n",
      "Epoch 98/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.5649 - sparse_categorical_accuracy: 0.8696 - val_loss: 0.5447 - val_sparse_categorical_accuracy: 0.8798\n",
      "Epoch 99/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.5617 - sparse_categorical_accuracy: 0.8700 - val_loss: 0.5416 - val_sparse_categorical_accuracy: 0.8800\n",
      "Epoch 100/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.5587 - sparse_categorical_accuracy: 0.8703 - val_loss: 0.5386 - val_sparse_categorical_accuracy: 0.8803\n",
      "Epoch 101/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.5557 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.5356 - val_sparse_categorical_accuracy: 0.8809\n",
      "Epoch 102/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.5527 - sparse_categorical_accuracy: 0.8712 - val_loss: 0.5327 - val_sparse_categorical_accuracy: 0.8814\n",
      "Epoch 103/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5499 - sparse_categorical_accuracy: 0.8716 - val_loss: 0.5299 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 104/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.5470 - sparse_categorical_accuracy: 0.8720 - val_loss: 0.5271 - val_sparse_categorical_accuracy: 0.8825\n",
      "Epoch 105/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5442 - sparse_categorical_accuracy: 0.8724 - val_loss: 0.5244 - val_sparse_categorical_accuracy: 0.8831\n",
      "Epoch 106/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5415 - sparse_categorical_accuracy: 0.8729 - val_loss: 0.5217 - val_sparse_categorical_accuracy: 0.8834\n",
      "Epoch 107/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5388 - sparse_categorical_accuracy: 0.8732 - val_loss: 0.5190 - val_sparse_categorical_accuracy: 0.8834\n",
      "Epoch 108/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5362 - sparse_categorical_accuracy: 0.8735 - val_loss: 0.5165 - val_sparse_categorical_accuracy: 0.8836\n",
      "Epoch 109/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5336 - sparse_categorical_accuracy: 0.8740 - val_loss: 0.5139 - val_sparse_categorical_accuracy: 0.8838\n",
      "Epoch 110/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5311 - sparse_categorical_accuracy: 0.8744 - val_loss: 0.5114 - val_sparse_categorical_accuracy: 0.8842\n",
      "Epoch 111/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5286 - sparse_categorical_accuracy: 0.8747 - val_loss: 0.5090 - val_sparse_categorical_accuracy: 0.8844\n",
      "Epoch 112/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5262 - sparse_categorical_accuracy: 0.8749 - val_loss: 0.5065 - val_sparse_categorical_accuracy: 0.8848\n",
      "Epoch 113/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5237 - sparse_categorical_accuracy: 0.8752 - val_loss: 0.5042 - val_sparse_categorical_accuracy: 0.8851\n",
      "Epoch 114/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5214 - sparse_categorical_accuracy: 0.8757 - val_loss: 0.5019 - val_sparse_categorical_accuracy: 0.8854\n",
      "Epoch 115/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5191 - sparse_categorical_accuracy: 0.8760 - val_loss: 0.4996 - val_sparse_categorical_accuracy: 0.8856\n",
      "Epoch 116/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5168 - sparse_categorical_accuracy: 0.8763 - val_loss: 0.4973 - val_sparse_categorical_accuracy: 0.8860\n",
      "Epoch 117/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5145 - sparse_categorical_accuracy: 0.8766 - val_loss: 0.4951 - val_sparse_categorical_accuracy: 0.8864\n",
      "Epoch 118/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5123 - sparse_categorical_accuracy: 0.8771 - val_loss: 0.4929 - val_sparse_categorical_accuracy: 0.8869\n",
      "Epoch 119/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5102 - sparse_categorical_accuracy: 0.8773 - val_loss: 0.4908 - val_sparse_categorical_accuracy: 0.8873\n",
      "Epoch 120/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5080 - sparse_categorical_accuracy: 0.8774 - val_loss: 0.4887 - val_sparse_categorical_accuracy: 0.8873\n",
      "Epoch 121/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5059 - sparse_categorical_accuracy: 0.8780 - val_loss: 0.4866 - val_sparse_categorical_accuracy: 0.8875\n",
      "Epoch 122/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5038 - sparse_categorical_accuracy: 0.8781 - val_loss: 0.4846 - val_sparse_categorical_accuracy: 0.8882\n",
      "Epoch 123/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5018 - sparse_categorical_accuracy: 0.8784 - val_loss: 0.4826 - val_sparse_categorical_accuracy: 0.8884\n",
      "Epoch 124/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4998 - sparse_categorical_accuracy: 0.8788 - val_loss: 0.4807 - val_sparse_categorical_accuracy: 0.8886\n",
      "Epoch 125/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4978 - sparse_categorical_accuracy: 0.8789 - val_loss: 0.4787 - val_sparse_categorical_accuracy: 0.8886\n",
      "Epoch 126/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4959 - sparse_categorical_accuracy: 0.8793 - val_loss: 0.4768 - val_sparse_categorical_accuracy: 0.8888\n",
      "Epoch 127/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4940 - sparse_categorical_accuracy: 0.8796 - val_loss: 0.4749 - val_sparse_categorical_accuracy: 0.8889\n",
      "Epoch 128/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4921 - sparse_categorical_accuracy: 0.8802 - val_loss: 0.4731 - val_sparse_categorical_accuracy: 0.8891\n",
      "Epoch 129/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4903 - sparse_categorical_accuracy: 0.8803 - val_loss: 0.4713 - val_sparse_categorical_accuracy: 0.8893\n",
      "Epoch 130/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4884 - sparse_categorical_accuracy: 0.8805 - val_loss: 0.4695 - val_sparse_categorical_accuracy: 0.8894\n",
      "Epoch 131/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4866 - sparse_categorical_accuracy: 0.8807 - val_loss: 0.4677 - val_sparse_categorical_accuracy: 0.8900\n",
      "Epoch 132/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4849 - sparse_categorical_accuracy: 0.8812 - val_loss: 0.4660 - val_sparse_categorical_accuracy: 0.8903\n",
      "Epoch 133/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4831 - sparse_categorical_accuracy: 0.8813 - val_loss: 0.4643 - val_sparse_categorical_accuracy: 0.8905\n",
      "Epoch 134/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4814 - sparse_categorical_accuracy: 0.8817 - val_loss: 0.4626 - val_sparse_categorical_accuracy: 0.8906\n",
      "Epoch 135/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4797 - sparse_categorical_accuracy: 0.8817 - val_loss: 0.4609 - val_sparse_categorical_accuracy: 0.8909\n",
      "Epoch 136/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4780 - sparse_categorical_accuracy: 0.8819 - val_loss: 0.4593 - val_sparse_categorical_accuracy: 0.8913\n",
      "Epoch 137/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4764 - sparse_categorical_accuracy: 0.8823 - val_loss: 0.4577 - val_sparse_categorical_accuracy: 0.8915\n",
      "Epoch 138/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4748 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.4561 - val_sparse_categorical_accuracy: 0.8919\n",
      "Epoch 139/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4732 - sparse_categorical_accuracy: 0.8827 - val_loss: 0.4545 - val_sparse_categorical_accuracy: 0.8923\n",
      "Epoch 140/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4716 - sparse_categorical_accuracy: 0.8829 - val_loss: 0.4530 - val_sparse_categorical_accuracy: 0.8927\n",
      "Epoch 141/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4700 - sparse_categorical_accuracy: 0.8832 - val_loss: 0.4515 - val_sparse_categorical_accuracy: 0.8929\n",
      "Epoch 142/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4685 - sparse_categorical_accuracy: 0.8831 - val_loss: 0.4500 - val_sparse_categorical_accuracy: 0.8927\n",
      "Epoch 143/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4670 - sparse_categorical_accuracy: 0.8833 - val_loss: 0.4485 - val_sparse_categorical_accuracy: 0.8929\n",
      "Epoch 144/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4655 - sparse_categorical_accuracy: 0.8836 - val_loss: 0.4470 - val_sparse_categorical_accuracy: 0.8931\n",
      "Epoch 145/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4640 - sparse_categorical_accuracy: 0.8838 - val_loss: 0.4456 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 146/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4626 - sparse_categorical_accuracy: 0.8838 - val_loss: 0.4442 - val_sparse_categorical_accuracy: 0.8934\n",
      "Epoch 147/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4611 - sparse_categorical_accuracy: 0.8839 - val_loss: 0.4428 - val_sparse_categorical_accuracy: 0.8932\n",
      "Epoch 148/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4597 - sparse_categorical_accuracy: 0.8843 - val_loss: 0.4414 - val_sparse_categorical_accuracy: 0.8932\n",
      "Epoch 149/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4583 - sparse_categorical_accuracy: 0.8845 - val_loss: 0.4400 - val_sparse_categorical_accuracy: 0.8936\n",
      "Epoch 150/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.4570 - sparse_categorical_accuracy: 0.8847 - val_loss: 0.4387 - val_sparse_categorical_accuracy: 0.8938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c7a4ddfd00>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(x_train_2_c, y_train_2, batch_size=128, epochs=150, verbose=1, validation_data=(x_valid_2_c, y_valid_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cc394d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4387 - sparse_categorical_accuracy: 0.8938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.438679039478302, 0.8938000202178955]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(x_valid_2_c,y_valid_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
